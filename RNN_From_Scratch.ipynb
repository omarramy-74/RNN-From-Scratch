{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "dcdmApzA9BV4"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Intialize Random arrays**"
      ],
      "metadata": {
        "id": "aCcuXU9VDfGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 1\n",
        "hidden_dim = 3\n",
        "output_dim = 1\n",
        "\n",
        "wx = np.random.randn(hidden_dim, input_dim) * np.sqrt(1/input_dim)\n",
        "wh = np.random.randn(hidden_dim, hidden_dim) * np.sqrt(1/hidden_dim)\n",
        "wo = np.random.randn(output_dim,hidden_dim) * np.sqrt(1/hidden_dim)\n",
        "\n",
        "print(f\"input->hidden Weights :\\n {wx } \\n\")\n",
        "print(f\"hidden->hidden weights :\\n {wh } \\n\")\n",
        "print(f\"hidden->output weights :\\n {wo } \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BSoGfpF9GeQ",
        "outputId": "db00f713-7706-4ea9-f163-77d942749a5e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input->hidden Weights :\n",
            " [[-1.12842626]\n",
            " [ 0.13693645]\n",
            " [-0.01567228]] \n",
            "\n",
            "hidden->hidden weights :\n",
            " [[ 0.40316286  0.37694561 -0.00980171]\n",
            " [-1.47310901  0.65082041 -0.17920119]\n",
            " [ 0.92837611 -0.36532238  0.31541256]] \n",
            "\n",
            "hidden->output weights :\n",
            " [[ 0.44378544  0.25123416 -0.23855756]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bx = np.zeros((hidden_dim, 1))\n",
        "by = np.zeros((output_dim, 1))"
      ],
      "metadata": {
        "id": "vVocgzDXCaPP"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Activation Functions**"
      ],
      "metadata": {
        "id": "feoukDmtDihn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "def dissigmoid(x):\n",
        "  s = sigmoid(x)\n",
        "  return s * (1-s)"
      ],
      "metadata": {
        "id": "kQuFeapn-Kyk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Forward Prop Function**"
      ],
      "metadata": {
        "id": "8EBoFzuGDl7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_prop(x_seq):\n",
        "  T = len(x_seq)\n",
        "  h = {}\n",
        "  z = {}\n",
        "  y = {}\n",
        "  h[-1] = np.zeros((hidden_dim,1))\n",
        "  for t in range(T):\n",
        "    x_t = x_seq[t].reshape(-1, 1)\n",
        "    z[t] = np.dot(wx,x_t) + np.dot(wh,h[t-1]) + bx\n",
        "    h[t] = sigmoid(z[t])\n",
        "    y[t] = np.dot(wo,h[t]) + by\n",
        "  return h, y , z"
      ],
      "metadata": {
        "id": "uB4aaGbE_J7-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Loss Function**"
      ],
      "metadata": {
        "id": "Za7Z5zfIFZJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y, y_seq):\n",
        "  loss = 0.0\n",
        "  for t in range(len(y_seq)):\n",
        "    loss += 0.5 * (y[t]-y_seq[t])**2\n",
        "  return loss"
      ],
      "metadata": {
        "id": "txJOlZmxDdYB"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Backward Prop**"
      ],
      "metadata": {
        "id": "K6zCynjnFjtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_prob(x_seq, y_seq, h, y, z):\n",
        "  T = len(x_seq)\n",
        "  dWx = np.zeros_like(wx)\n",
        "  dWh = np.zeros_like(wh)\n",
        "  dWy = np.zeros_like(wo)\n",
        "  dbx = np.zeros_like(bx)\n",
        "  dby = np.zeros_like(by)\n",
        "  dh_next = np.zeros((hidden_dim, 1))\n",
        "  for t in reversed(range(T)):\n",
        "    x_t = x_seq[t].reshape(-1,1)\n",
        "    y_t = y_seq[t]\n",
        "    dy = ( y[t] - y_t)\n",
        "    dWy = np.dot(dy,h[t].T)\n",
        "    dby += dy\n",
        "    dz = (np.dot(wo.T,dy)+np.dot(wh.T,dh_next))*dissigmoid(z[t])\n",
        "    dWx += np.dot(dz,x_t.T)\n",
        "    dWh += np.dot(dz,h[t-1].T)\n",
        "    dbx += dz\n",
        "    dh_next = dz\n",
        "  return dWx, dWh, dWy, dbx, dby"
      ],
      "metadata": {
        "id": "a84oN42_FjK0"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Update param function**"
      ],
      "metadata": {
        "id": "htMH9gfuM4_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_param(dWx,dWh,dWy,dbx,dby,lr=0.01):\n",
        "  global wx,wy,wh,bx,by\n",
        "  wx -= lr*dWx\n",
        "  wo -= lr*dWy\n",
        "  wh -= lr*dWh\n",
        "  bx -= lr*dbx\n",
        "  by -= lr*dby"
      ],
      "metadata": {
        "id": "8Gm95zggM7Lp"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [np.array([1]), np.array([2])]\n",
        "target = [np.array([[0.5]]), np.array([[0.8]])]"
      ],
      "metadata": {
        "id": "vexqjNz1NUv0"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEp_WjInNZ8p",
        "outputId": "5497ad32-c02c-440f-e123-289ae34b332c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1]), array([2])]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Train Loop**"
      ],
      "metadata": {
        "id": "TFtpHNv9NdvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2000):\n",
        "  h,y,z = forward_prop(x)\n",
        "  current_loss = loss(y,target)\n",
        "  dWx, dWh, dWy, dbx, dby = backward_prob(x,target,h,y,z)\n",
        "  update_param(dWx,dWh,dWy,dbx,dby)\n",
        "  if epoch % 100 == 0:\n",
        "    print(f\"Epoch {epoch} Loss {current_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRrZE0uRNbGN",
        "outputId": "24f23e67-7722-46a9-c320-ec16b40d9b74"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Loss [[0.34250106]]\n",
            "Epoch 100 Loss [[0.03610157]]\n",
            "Epoch 200 Loss [[0.03159182]]\n",
            "Epoch 300 Loss [[0.03063116]]\n",
            "Epoch 400 Loss [[0.02972769]]\n",
            "Epoch 500 Loss [[0.0286496]]\n",
            "Epoch 600 Loss [[0.02734849]]\n",
            "Epoch 700 Loss [[0.02582265]]\n",
            "Epoch 800 Loss [[0.02409911]]\n",
            "Epoch 900 Loss [[0.0222216]]\n",
            "Epoch 1000 Loss [[0.02024075]]\n",
            "Epoch 1100 Loss [[0.01820815]]\n",
            "Epoch 1200 Loss [[0.0161737]]\n",
            "Epoch 1300 Loss [[0.01418451]]\n",
            "Epoch 1400 Loss [[0.01228353]]\n",
            "Epoch 1500 Loss [[0.01050741]]\n",
            "Epoch 1600 Loss [[0.00888419]]\n",
            "Epoch 1700 Loss [[0.00743158]]\n",
            "Epoch 1800 Loss [[0.00615671]]\n",
            "Epoch 1900 Loss [[0.0050573]]\n"
          ]
        }
      ]
    }
  ]
}